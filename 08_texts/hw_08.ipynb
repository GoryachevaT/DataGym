{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import pymystem3\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import lognorm as sp_lognorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', sep=';', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;В молодой и дружный коллектив динамично раз...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности: &lt;/strong&gt;- Прием входя...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Федеральная сеть аптек &lt;/strong&gt;в с...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;strong&gt;Обязанности:&lt;/strong&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;раз...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;Производителю сантехники тм Domani Spa треб...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  target\n",
       "id                                                           \n",
       "0   <p>В молодой и дружный коллектив динамично раз...       0\n",
       "1   <p><strong>Обязанности: </strong>- Прием входя...       0\n",
       "2   <p><strong>Федеральная сеть аптек </strong>в с...       0\n",
       "3   <strong>Обязанности:</strong> <ul> <li> <p>раз...       0\n",
       "4   <p>Производителю сантехники тм Domani Spa треб...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31063, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16471\n",
       "1    14592\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', sep=';', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_wordlist(text):\n",
    "    text_wo_tags = re.sub(\"<[^>]*>\", \"\", text.lower())\n",
    "    text = re.sub('[^a-zA-Zа-яА-ЯёЁ]', ' ', text_wo_tags)\n",
    "    words = text.lower().strip().split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(words, stopWords):\n",
    "    new_words = [word for word in words if (word not in stopWords) and len(word) > 2]\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = pymystem3.Mystem()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_v2(words):    \n",
    "    new_words = [mystem.lemmatize(x)[0] for x in words]\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_v3(words):    \n",
    "    new_words = [wordnet_lemmatizer.lemmatize(x, pos=wordnet.VERB) for x in words]\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(df, stopWords):\n",
    "    \n",
    "    temp = df.copy()\n",
    "    temp['norm_test'] = temp['text'].apply(lambda x: text_to_wordlist(x))\n",
    "    print('v1 done')\n",
    "    temp['norm_test_v2'] = temp['norm_test'].apply(lambda x: clean(x, stopWords))\n",
    "    print('v2 done')\n",
    "    temp['norm_test_v3'] = temp['norm_test_v2'].apply(lambda x: clean_v2(x))\n",
    "    print('v3 done')\n",
    "    temp['norm_test_v4'] = temp['norm_test_v3'].apply(lambda x: clean_v3(x))\n",
    "    print('v4 done')\n",
    "    temp['joined_text'] = temp['norm_test_v4'].apply(lambda x: ' '.join(x))\n",
    "    joined_text = temp['joined_text'].tolist()\n",
    "    \n",
    "    return joined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 done\n",
      "v2 done\n",
      "v3 done\n",
      "v4 done\n",
      "CPU times: user 2min 6s, sys: 39.7 s, total: 2min 46s\n",
      "Wall time: 6min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stopWords = stopwords.words(['russian', 'english'])\n",
    "train_joined_text = preproc_data(train, stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(train_joined_text)\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf, open('tf_idf.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': sp_lognorm(4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   26.9s finished\n",
      "/Users/antonina.goryacheva/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'penalty': ['l1', 'l2'], 'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1a36561a90>},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_searcher = RandomizedSearchCV(model, param_grid, n_iter=20, \n",
    "                                     random_state=42,\n",
    "                                     scoring='roc_auc', \n",
    "                                     n_jobs=-1, cv=cv, \n",
    "                                     verbose=2)\n",
    "\n",
    "random_searcher.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.923122445211833, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923324224726257"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = random_searcher.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open('best_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valid = best_model.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907754548963311"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, pred_valid[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = pickle.load(open('best_model.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31063</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;В крупную компанию по организации и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31064</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31065</th>\n",
       "      <td>&lt;p&gt; &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31066</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31067</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Вакансия СРОЧНАЯ!&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "id                                                      \n",
       "31063  <p><strong>В крупную компанию по организации и...\n",
       "31064  <p><strong>Обязанности:</strong></p> <ul> <li>...\n",
       "31065  <p> </p> <p><strong>Обязанности:</strong></p> ...\n",
       "31066  <p><strong>Обязанности:</strong></p> <ul> <li>...\n",
       "31067  <p><strong>Вакансия СРОЧНАЯ!</strong></p> <p><..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31064, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 done\n",
      "v2 done\n",
      "v3 done\n",
      "v4 done\n",
      "CPU times: user 1min 48s, sys: 33.9 s, total: 2min 22s\n",
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stopWords = stopwords.words(['russian', 'english'])\n",
    "test_joined_text = preproc_data(test, stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf.transform(test_joined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('text', axis=1).to_csv('submission_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

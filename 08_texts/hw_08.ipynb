{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import pymystem3\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import lognorm as sp_lognorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', sep=';', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;В молодой и дружный коллектив динамично раз...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности: &lt;/strong&gt;- Прием входя...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Федеральная сеть аптек &lt;/strong&gt;в с...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;strong&gt;Обязанности:&lt;/strong&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;раз...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;Производителю сантехники тм Domani Spa треб...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  target\n",
       "id                                                           \n",
       "0   <p>В молодой и дружный коллектив динамично раз...       0\n",
       "1   <p><strong>Обязанности: </strong>- Прием входя...       0\n",
       "2   <p><strong>Федеральная сеть аптек </strong>в с...       0\n",
       "3   <strong>Обязанности:</strong> <ul> <li> <p>раз...       0\n",
       "4   <p>Производителю сантехники тм Domani Spa треб...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31063, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16471\n",
       "1    14592\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', sep=';', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31064, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_wordlist(text):\n",
    "    text_wo_tags = re.sub(\"<[^>]*>\", \"\", text.lower())\n",
    "    text = re.sub('[^a-zA-Zа-яА-ЯёЁ]', ' ', text_wo_tags)\n",
    "    words = text.lower().strip().split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(words, stopWords):\n",
    "    new_words = [word for word in words if (word not in stopWords) and len(word) > 2]\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = pymystem3.Mystem()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_v2(words):    \n",
    "    new_words = [mystem.lemmatize(x)[0] for x in words]\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_v3(words):    \n",
    "    new_words = [wordnet_lemmatizer.lemmatize(x, pos=wordnet.VERB) for x in words]\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(df, stopWords):\n",
    "    \n",
    "    temp = df.copy()\n",
    "    temp['norm_test'] = temp['text'].apply(lambda x: text_to_wordlist(x))\n",
    "    print('v1 done')\n",
    "    temp['norm_test_v2'] = temp['norm_test'].apply(lambda x: clean(x, stopWords))\n",
    "    print('v2 done')\n",
    "    temp['norm_test_v3'] = temp['norm_test_v2'].apply(lambda x: clean_v2(x))\n",
    "    print('v3 done')\n",
    "    temp['norm_test_v4'] = temp['norm_test_v3'].apply(lambda x: clean_v3(x))\n",
    "    print('v4 done')\n",
    "    temp['joined_text'] = temp['norm_test_v4'].apply(lambda x: ' '.join(x))\n",
    "    joined_text = temp['joined_text'].tolist()\n",
    "    \n",
    "    return joined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 done\n",
      "v2 done\n",
      "v3 done\n",
      "v4 done\n",
      "CPU times: user 1min 55s, sys: 36.9 s, total: 2min 32s\n",
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stopWords = stopwords.words(['russian', 'english'])\n",
    "train_joined_text = preproc_data(train, stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 done\n",
      "v2 done\n",
      "v3 done\n",
      "v4 done\n",
      "CPU times: user 1min 56s, sys: 37.8 s, total: 2min 34s\n",
      "Wall time: 5min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_joined_text = preproc_data(test, stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepr_train = pd.DataFrame(train_joined_text, columns=['text'])\n",
    "prepr_train['target'] = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepr_test = pd.DataFrame(test_joined_text, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepr_train.to_csv('prepr_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepr_test.to_csv('prepr_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read preproc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>молодой дружный коллектив динамично развиватьс...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>обязанность прием входить звонок заявка обрабо...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>федеральный сеть аптека связь активный расшире...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>обязанность разработка проектный рабочий докум...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>производитель сантехник domani spa требоваться...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  молодой дружный коллектив динамично развиватьс...       0\n",
       "1  обязанность прием входить звонок заявка обрабо...       0\n",
       "2  федеральный сеть аптека связь активный расшире...       0\n",
       "3  обязанность разработка проектный рабочий докум...       0\n",
       "4  производитель сантехник domani spa требоваться...       1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepr_train = pd.read_csv('prepr_train.csv')\n",
    "prepr_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>крупный компания организация приготовление кор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>обязанность обеспечение необходимый функционал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>обязанность отгрузка прием товар склад склад к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>обязанность приготовление холодный горячий блю...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>вакансия срочный внимание просьба подробно изу...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  крупный компания организация приготовление кор...\n",
       "1  обязанность обеспечение необходимый функционал...\n",
       "2  обязанность отгрузка прием товар склад склад к...\n",
       "3  обязанность приготовление холодный горячий блю...\n",
       "4  вакансия срочный внимание просьба подробно изу..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv('prepr_test.csv')\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prepr_train.drop('target', axis=1)\n",
    "y = prepr_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = X_train['text'].tolist()\n",
    "valid_list = X_valid['text'].tolist()\n",
    "test_list = X_test['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = train_list + valid_list + test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<62127x73965 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5038040 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr_train = tfidf.transform(train_list)\n",
    "matr_valid = tfidf.transform(valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {'n_estimators':  range(150, 400, 50),\n",
    "#           'learning_rate': [.1],\n",
    "#           'max_depth': range(2, 8, 2),\n",
    "#           'subsample': [ .5, .6, .95, 1, .1, .3],\n",
    "#           'gamma': [0, .05, .1, .2, .25, 0.01, 0.02],\n",
    "#           'colsample_bytree': [1, .10, .50],\n",
    "#           'colsample_bylevel': [1, .3, .1, .5, .7, .9],\n",
    "#           'reg_alpha': [0, 0.1, 0.3, 0.5, 0.7, 1],\n",
    "#           'reg_lambda': [0, 0.1, 0.3, 0.5, 0.7, 1],\n",
    "#           'scale_pos_weight': [1, 10, 25, 50]}\n",
    "\n",
    "# clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('clf', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer()),\n",
    "#     ('logreg', LogisticRegression(random_state=42)) \n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(tfidf, open('tf_idf.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#    # 'tfidf__ngram_range': range(1, 3), \n",
    "#    # 'tfidf__max_df': random.uniform(0, 1),\n",
    "#    # 'tfidf__max_features': range(5000, 45000), \n",
    "#     'clf__penalty': ['l1', 'l2'],\n",
    "#     'clf__C': sp_lognorm(4)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 131.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=30, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': range(150, 400, 50), 'learning_rate': [0.1], 'max_depth': range(2, 10, 2), 'subsample': [0.5, 0.6, 0.95, 1, 0.1, 0.3], 'gamma': [0, 0.05, 0.1, 0.2, 0.25, 0.01, 0.02], 'colsample_bytree': [1, 0.1, 0.5], 'colsample_bylevel': [1, 0.3, 0.1, 0.5, 0.7, 0.9], 'reg_alpha': [0, 0.1, 0.3, 0.5, 0.7, 1], 'reg_lambda': [0, 0.1, 0.3, 0.5, 0.7, 1], 'scale_pos_weight': [1, 10, 25, 50]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Задаем схему кросс-валидации\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Запускаем поиск гиперпараметров\n",
    "hyper_search = RandomizedSearchCV(pipe, param_grid, n_iter=30, scoring='roc_auc', cv=cv,\n",
    "                                  n_jobs=-1, refit=True, random_state=42, verbose=2)\n",
    "\n",
    "hyper_search.fit(matr_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1,\n",
       " 'scale_pos_weight': 50,\n",
       " 'reg_lambda': 0.1,\n",
       " 'reg_alpha': 0.5,\n",
       " 'n_estimators': 300,\n",
       " 'max_depth': 8,\n",
       " 'learning_rate': 0.1,\n",
       " 'gamma': 0.25,\n",
       " 'colsample_bytree': 0.5,\n",
       " 'colsample_bylevel': 1}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9897515273504104"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = hyper_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open('best_model_xgb.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valid = best_model.predict_proba(matr_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912249697249966"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, pred_valid[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = pickle.load(open('best_model_xgb.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr_test = tfidf.transform(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model.predict_proba(matr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('text', axis=1).to_csv('submission_5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
